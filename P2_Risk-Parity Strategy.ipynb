{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 Risk Parity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this part, our asset groups include one gold ETF named GLD and one stock  ETF tracking the NASDAQUE 100 named QQQ.\n",
    "# We are interested in gold since we guess that the gold price should be stable across the time. Bond might be turned into junk bond while the gold could not be downgraded.\n",
    "# The top holdings of the QQQ ETF are all technology stocks which we are interested in.\n",
    "# The market cap for these two ETFs are similar to some extent.\n",
    "# The time horizon of our dataset starts from 2007-12-31 to 2017-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part, we define some cornerstones of this project such as optimization function for risk budgeting approach\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance as yf\n",
    "yf.pdr_override() \n",
    "import datetime \n",
    "from collections import OrderedDict\n",
    "from datetime import timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def cov_ewma(ret_assets, lamda = 0.94):\n",
    "    ret_mat = ret_assets.values\n",
    "    T = len(ret_assets)\n",
    "    coeff = np.zeros((T,1))\n",
    "    S = ret_assets.cov()\n",
    "    for i in range(1, T):\n",
    "#        S = lamda * S  + (1-lamda)*np.matmul(ret_mat[i-1,:].reshape((-1,1)), \n",
    "#                          ret_mat[i-1,:].reshape((1,-1)))\n",
    "        S = lamda * S  + (1-lamda)* (ret_mat[i-1,:].reshape((-1,1)) @ ret_mat[i-1,:].reshape((1,-1)) )\n",
    "        \n",
    "        coeff[i] = (1-lamda)*lamda**(i)\n",
    "    return S/np.sum(coeff)\n",
    "\n",
    "    \n",
    "# risk budgeting approach optimisation object function\n",
    "def obj_fun(W, cov_assets, risk_budget):\n",
    "    var_p = np.dot(W.transpose(), np.dot(cov_assets, W))\n",
    "    sigma_p = np.sqrt(var_p)\n",
    "    risk_contribution = W*np.dot(cov_assets, W)/sigma_p\n",
    "    risk_contribution_percent = risk_contribution/sigma_p\n",
    "    return np.sum((risk_contribution_percent-risk_budget)**2)\n",
    "\n",
    "\n",
    "# calculate risk budgeting portfolio weight give risk budget\n",
    "def riskparity_opt(ret_assets, risk_budget, lamda, method='ewma',Wts_min=0.0, leverage=False):\n",
    "    # number of assets\n",
    "    num_assets = ret_assets.shape[1]\n",
    "    # covariance matrix of asset returns\n",
    "    if method=='ewma':\n",
    "        cov_assets = cov_ewma(ret_assets, lamda)\n",
    "    elif method=='ma':\n",
    "        cov_assets = ret_assets.cov()\n",
    "    else:\n",
    "        cov_assets = cov_ewma(ret_assets, lamda)        \n",
    "    \n",
    "    # initial weights\n",
    "    w0 = 1.0 * np.ones((num_assets, 1)) / num_assets\n",
    "    # constraints\n",
    "    #cons = ({'type': 'eq', 'fun': cons_sum_weight}, {'type': 'ineq', 'fun': cons_long_only_weight})\n",
    "    if leverage == True:\n",
    "        c_ = ({'type':'eq', 'fun': lambda W: sum(W)-2. }, # Sum of weights = 200%\n",
    "              {'type':'ineq', 'fun': lambda W: W-Wts_min}) # weights greater than min wts\n",
    "    else:\n",
    "        c_ = ({'type':'eq', 'fun': lambda W: sum(W)-1. }, # Sum of weights = 100%\n",
    "              {'type':'ineq', 'fun': lambda W: W-Wts_min}) # weights greater than min wts\n",
    "    # portfolio optimisation\n",
    "    return minimize(obj_fun, w0, args=(cov_assets, risk_budget), method='SLSQP', constraints=c_)\n",
    "\n",
    "\n",
    "# function to get the price data from yahoo finance \n",
    "def getDataBatch(tickers, startdate, enddate):\n",
    "  def getData(ticker):\n",
    "    return (pdr.get_data_yahoo(ticker, start=startdate, end=enddate))\n",
    "  datas = map(getData, tickers)\n",
    "  return(pd.concat(datas, keys=tickers, names=['Ticker', 'Date']))\n",
    "\n",
    "\n",
    "# function to get the return data calculated from price data \n",
    "# retrived from yahoo finance \n",
    "def getReturns(tickers, start_dt, end_dt, freq='monthly'): \n",
    "    px_data = getDataBatch(tickers, start_dt, end_dt)\n",
    "    # Isolate the `Adj Close` values and transform the DataFrame\n",
    "    px = px_data[['Adj Close']].reset_index().pivot(index='Date', \n",
    "                           columns='Ticker', values='Adj Close')\n",
    "    if (freq=='monthly'):\n",
    "        px = px.resample('M').last()\n",
    "        \n",
    "    # Calculate the daily/monthly percentage change\n",
    "    ret = px.pct_change().dropna()\n",
    "    \n",
    "    ret.columns = tickers\n",
    "    return(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical price data of our two groups of assets\n",
    "Flag_downloadData = False\n",
    "# define the time period \n",
    "start_dt = datetime.datetime(2007, 12, 31)\n",
    "end_dt = datetime.datetime(2017, 12, 31)\n",
    "\n",
    "if Flag_downloadData:\n",
    "#    price_SPX = pdr.get_data_yahoo('SPY', start=start_dt, end=end_dt)\n",
    "#    price_AGG = pdr.get_data_yahoo('AGG', start=start_dt, end=end_dt)\n",
    "    #\n",
    "    Ticker_AllAsset = ['QQQ', 'GLD']\n",
    "    stock_data = getDataBatch(Ticker_AllAsset, start_dt, end_dt)\n",
    "    # Isolate the `Adj Close` values and transform the DataFrame\n",
    "    price_AllAsset = stock_data.reset_index().pivot(index='Date', columns='Ticker', values='Adj Close')\n",
    "    # Merge equity data with bond data\n",
    "    # merging/joining dataframe\n",
    "#    frames = [price_SPX['Adj Close'], price_AGG['Adj Close']]# this creats a list of two frames\n",
    "#    price_AllAsset1 = pd.concat(frames, axis=1, join='inner') # merge only the common rows\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter('QQQ-GLD.xlsx', engine='xlsxwriter')\n",
    "    price_AllAsset.to_excel(writer, sheet_name='Price',startrow=0, startcol=0, header=True, index=True)\n",
    "else:\n",
    "    price_AllAsset = pd.read_excel('QQQ-GLD.xlsx', sheet_name='Price',\n",
    "                    header=0, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this part, we decide to use the window equal to 30 instead of 90\n",
    "# The current running result allows for the shorting activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate ARP excess returns\n",
    "ret_assets = price_AllAsset.pct_change().dropna()\n",
    "ret_assets_demean = ret_assets - ret_assets.mean()\n",
    "num_assets = ret_assets.shape[1]\n",
    "\n",
    "lamda = 0.94\n",
    "SS = cov_ewma(ret_assets_demean, lamda)\n",
    "\n",
    "# Construct risk parity portfolio\n",
    "# portfolio dates - this defines the first date of portfolio construction\n",
    "datestr = ret_assets.index[ret_assets.index >= '2008-03-31']\n",
    "# previous month\n",
    "mth_previous = datestr[0]\n",
    "# initialise portfolio weights matrix\n",
    "wts = pd.DataFrame(index=datestr, columns=ret_assets.columns)\n",
    "# initialise portfolio return matrix\n",
    "ret_riskParity = pd.DataFrame(index=datestr, columns=['Risk Parity'])\n",
    "# how many rolling calendar days to use for covariance calculation\n",
    "window = 30\n",
    "Wts_min = 0.0\n",
    "risk_budget = 1.0/num_assets*np.ones([1,num_assets]) #risk-party\n",
    "#risk_budget = [0.7, 0.4]\n",
    "leverage = True\n",
    "varmodel = 'ewma'\n",
    "\n",
    "\n",
    "for t in datestr:\n",
    "    # construct risk budgeting portfolio and re-balance on monthly basis\n",
    "    if t.month==mth_previous:\n",
    "        # keep the same portfolio weights within the month\n",
    "        wts.loc[t] = wts.iloc[wts.index.get_loc(t)-1]\n",
    "    else:\n",
    "        # update the value of the previous month \n",
    "        mth_previous = t.month\n",
    "        # re-balance the portfolio at the start of the month\n",
    "        \n",
    "        t_begin = t - timedelta(days=window)\n",
    "        ret_used = ret_assets.loc[t_begin:t,:]\n",
    "        wts.loc[t] = riskparity_opt(ret_used, risk_budget, lamda, varmodel, Wts_min, leverage).x\n",
    "    # calculate risk budgeting portfolio returns\n",
    "    ret_riskParity.loc[t] = np.sum(wts.loc[t] * ret_assets.loc[t])\n",
    "    \n",
    "# Due to precision issue, wts could be a tiny negative number instead of zero, make them zero\n",
    "wts[wts<0]=0.0\n",
    "# Construct equal weighted portfolio\n",
    "ret_equalwted = pd.DataFrame(np.sum(1.0*ret_assets[ret_assets.index>=datestr[0]]/num_assets, axis=1), columns=['Equal Weighted'])\n",
    "# Construct 60/40 weighted portfolio\n",
    "#ret_equalwted = pd.DataFrame(np.sum(1.0*ret_assets[ret_assets.index>=datestr[0]]/num_assets, axis=1), columns=['Equal Weighted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance stats such as sharpe ratio and the cumulative returns\n",
    "ret_cumu_assets = (ret_assets + 1).cumprod()\n",
    "ret_cumu_riskP = (ret_riskParity + 1).cumprod()\n",
    "ret_cumu_equalwt = (ret_equalwted + 1).cumprod()\n",
    "\n",
    "ret_annual_assets = ret_cumu_assets.iloc[-1]**(250/len(ret_cumu_assets))-1\n",
    "std_annual_assets = ret_assets.std()*np.sqrt(250)\n",
    "sharpe_ratio_assets = ret_annual_assets/std_annual_assets\n",
    "\n",
    "ret_annual_riskP = ret_cumu_riskP.iloc[-1]**(250/len(ret_cumu_riskP))-1\n",
    "std_annual_riskP = ret_riskParity.std()*np.sqrt(250)\n",
    "sharpe_ratio_riskP = ret_annual_riskP/std_annual_riskP\n",
    "\n",
    "ret_annual_equalwt = ret_cumu_equalwt.iloc[-1]**(250/len(ret_cumu_equalwt))-1\n",
    "std_annual_equalwt = ret_equalwted.std()*np.sqrt(250)\n",
    "sharpe_ratio_equalwt = ret_annual_equalwt/std_annual_equalwt\n",
    "\n",
    "#sharpe_table = [sharpe_ratio_riskP, sharpe_ratio_equalwt]\n",
    "sharpe_table = pd.Series(OrderedDict((('risk_parity', sharpe_ratio_riskP.values),\n",
    "                 ('equal_wted', sharpe_ratio_equalwt.values),\n",
    "                 )))\n",
    "sharpe_table1 = pd.Series(OrderedDict((('risk_parity', sharpe_ratio_riskP.values),\n",
    "                 ('QQQ', sharpe_ratio_assets[0]),\n",
    "                 ('GLD', sharpe_ratio_assets[1]),\n",
    "                 )))\n",
    "print('sharpe ratio of different strategies:\\n',sharpe_table)\n",
    "print('\\nsharpe ratio of strategies vs assets:\\n',sharpe_table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the portfolio cumulative returns based on whether short sale could be used\n",
    "# In this part, we use the plot to better illustrate the results\n",
    "if leverage:\n",
    "        figure_count = 1\n",
    "        plt.figure(figure_count)\n",
    "        figure_count = figure_count+1\n",
    "        pd.concat([ret_cumu_riskP, ret_cumu_equalwt], axis=1).plot()\n",
    "        plt.ylabel('Cumulative Return')\n",
    "        plt.title('Leverage cumulative return for different strategies',fontsize=10)\n",
    "        plt.show()\n",
    "        plt.savefig('Cumulative returns for different strategies_leverage')\n",
    "        # compare the portfolio cumulative returns vs. asset returns\n",
    "        plt.figure(figure_count)\n",
    "        figure_count = figure_count+1\n",
    "        pd.concat([ret_cumu_riskP, ret_cumu_assets], axis=1).plot()\n",
    "        plt.ylabel('Cumulative Return')\n",
    "        plt.title('Leverage returns between assets',fontsize=10)\n",
    "        plt.show()\n",
    "        plt.savefig('Cumulative returns for different strategies_leverage')\n",
    "        # plot the historical weights of the assets\n",
    "        # area plot showing the weights\n",
    "        plt.figure(figure_count)\n",
    "        figure_count = figure_count + 1\n",
    "        wts.plot.area()\n",
    "        plt.title('Leverage asset weights',fontsize=10)\n",
    "        plt.ylabel('asset weights')\n",
    "        plt.savefig('leverage asset weights')\n",
    "else:\n",
    "    \n",
    "    figure_count = 1\n",
    "    plt.figure(figure_count)\n",
    "    figure_count = figure_count+1\n",
    "    pd.concat([ret_cumu_riskP, ret_cumu_equalwt], axis=1).plot()\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.title('Cumulative return for different strategies',fontsize=10)\n",
    "    plt.show()\n",
    "    plt.savefig('Cumulative returns for different strategies')\n",
    "    # compare the portfolio cumulative returns vs. asset returns\n",
    "    plt.figure(figure_count)\n",
    "    figure_count = figure_count+1\n",
    "    pd.concat([ret_cumu_riskP, ret_cumu_assets], axis=1).plot()\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.title('Returns between assets',fontsize=10)\n",
    "    plt.show()\n",
    "    plt.savefig('Cumulative returns for different strategies')\n",
    "    # plot the historical weights of the assets\n",
    "    # area plot showing the weights\n",
    "    plt.figure(figure_count)\n",
    "    figure_count = figure_count + 1\n",
    "    wts.plot.area()\n",
    "    plt.title('Asset weights',fontsize=10)\n",
    "    plt.ylabel('asset weights')\n",
    "    plt.savefig('Asset weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some insights from the results\n",
    "# No matter the shorting is allowed, the sharpe ratio of the risk parity is always higher than that of the equally weighted strategy and each asset.\n",
    "# Therefore, the risk parity strategy is more optimal than equally weighted strategy from the perspective of risk budgeting \n",
    "# The sharpe ratio of the risk parity is higher when the shorting is not allowed. We guess that the reason for this could be: the price trend of these two assets has relative big difference, sometimes exists negative relationship. Therefore, when we use the more risky shorting investment strategy, the excess return we could get fails to compensate the increased risk we have taken.\n",
    "# When comparing the cumulative return, risk parity beats the equally weighted strategy whenever using the shortings.\n",
    "# The trade-off decision should depend on the degree of investor's risk aversion. If you are a risk-lover, risk parity stratgy with short sales will be definitely the best choice for you. If you are risk-averse, you definitely focus more on the excess return per unit of risk. In this case, you should choose the risk parity strategy without short sales which has the highest sharpe ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More to think about:\n",
    "# How to choose the assets groups to get a higher sharpe ratio using the risk parity strategy?\n",
    "# Is it more optimal to use the risk parity strategy when choosing asset groups with higher correlation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
