{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Project 1 Minimizing Tracking Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We construct our own index by selecting 30 stocks with top market cap in technology sector\n",
    "# The reasons for choosing the technology stock include:\n",
    "# 1. High growing opportunity\n",
    "# 2. High market capitalization\n",
    "# 3. Actively traded\n",
    "# 4. Great investments\n",
    "# We simply use the equally-weighted approach to get the index price level. The time of the data starts from the 2000-12-31 to 2017-12-31\n",
    "# The training data starts from 2000-12-31 to 2008-12-31 while the testing data starts from 2009-1-1 to 2017-12-31.\n",
    "# We devide our dataset based on roughly two economy cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this part is to get ready for the dataset\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import scipy.io as spio\n",
    "#pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance as yf\n",
    "yf.pdr_override() \n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import itertools\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def getDataBatch(tickers, startdate, enddate):\n",
    "  def getData(ticker):\n",
    "    return (pdr.get_data_yahoo(ticker, start=startdate, end=enddate))\n",
    "  datas = map(getData, tickers)\n",
    "  return(pd.concat(datas, keys=tickers, names=['Ticker', 'Date']))\n",
    "get historical stock price data\n",
    "Flag_downloadData = False\n",
    "# define the time period \n",
    "start_dt = datetime.datetime(2000, 12, 31)\n",
    "end_dt = datetime.datetime(2017, 12, 31)\n",
    "\n",
    "tickers = ['AAPL', 'ADBE', 'AMAT', 'ANSS', 'ASML', 'CERN', 'CHKP', 'CSCO', 'CTSH', 'CTXS', 'FFIV', 'FISV', 'INTU', 'JKHY', 'LRCX', 'MCHP', 'MRVL', 'MSFT', 'MXIM', 'NOK', 'NTAP', 'NVDA', 'ORCL', 'QCOM', 'SNPS', 'SYMC', 'TSM', 'TTWO', 'VRSN', 'XLNX']\n",
    "# Marketcap-weighted\n",
    "# wts_Index = pd.Series([0.293082, 0.266411, 0.066398, 0.064882, 0.061179, 0.039640, 0.037962, 0.021618, 0.017907, 0.012936, 0.010914, 0.010704, 0.010243, 0.007324, 0.007010, 0.006689, 0.006155, 0.006048, 0.005852, 0.005632, 0.004735, 0.004723, 0.004713, 0.004401, 0.004303, 0.004135, 0.004012, 0.003501, 0.003468, 0.003424])\n",
    "# Equally-weighted\n",
    "wts_Index = pd.Series([1/30] * 30)\n",
    "\n",
    "if Flag_downloadData:\n",
    "    \n",
    "    stock_data = getDataBatch(tickers, start_dt, end_dt)\n",
    "    # Isolate the `Adj Close` values and transform the DataFrame\n",
    "    daily_close_px = stock_data.reset_index().pivot(index='Date', columns='Ticker', values='Adj Close')\n",
    "    # Marketcap-weighted\n",
    "    #index_close_px = pd.DataFrame(np.dot(daily_close_px.iloc[:,0:30], [0.293082, 0.266411, 0.066398, 0.064882, 0.061179, 0.039640, 0.037962, 0.021618, 0.017907, 0.012936, 0.010914, 0.010704, 0.010243, 0.007324, 0.007010, 0.006689, 0.006155, 0.006048, 0.005852, 0.005632, 0.004735, 0.004723, 0.004713, 0.004401, 0.004303, 0.004135, 0.004012, 0.003501, 0.003468, 0.003424]), index = daily_close_px.index.values)\n",
    "    # Equally-weighted\n",
    "    index_close_px = pd.DataFrame(np.dot(daily_close_px.iloc[:,0:30], [1/30] * 30), index = daily_close_px.index.values)\n",
    "    index_close_px.columns = ['Index']\n",
    "    \n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter('Price.xlsx', engine='xlsxwriter')\n",
    "    daily_close_px.to_excel(writer, sheet_name='PriceStock',startrow=0, startcol=0, header=True, index=True)\n",
    "    index_close_px.to_excel(writer, sheet_name='PriceIndex',startrow=0, startcol=0, header=True, index=True)\n",
    "else:\n",
    "    daily_close_px = pd.read_excel('Price.xlsx', sheet_name='PriceStock',\n",
    "                    header=0, index_col = 0)\n",
    "    index_close_px = pd.read_excel('Price.xlsx', sheet_name='PriceIndex',\n",
    "                    header=0, index_col = 0)\n",
    "\n",
    "plt.plot(index_close_px)\n",
    "plt.ylabel('Index Level')\n",
    "plt.xlabel('Years')\n",
    "plt.title('Steve Tech 30 Index')\n",
    "plt.savefig('Steve Tech 30 Index')\n",
    "# calculate the historical daily returns of each stocks and the index\n",
    "# daily_pct_change = daily_close_px.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next we want to construct a ETF fund by using the top 10 to 20 stock to track the index and minimize the tracking error.\n",
    "# We firstly use the training data to get the optimized weights and then use the optimized weights to claculate the tracking error of the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this part shows the step of calculating the covariance matrix of the training data\n",
    "# Choose top 20 stocks to build the portfolio and track the index\n",
    "# Returns\n",
    "ret_AllStock = daily_close_px.pct_change().dropna()\n",
    "ret_Idx = index_close_px.pct_change().dropna()\n",
    "ret_Idx.columns = ['Return']\n",
    "\n",
    "# Scale return data by a factor. It seems that the optimizer fails when the values are too close to 0\n",
    "scale = 1\n",
    "ret_AllStock = ret_AllStock*scale\n",
    "ret_Idx = ret_Idx*scale\n",
    "\n",
    "num_periods, num_stock = ret_AllStock.shape\n",
    "\n",
    "# Calulate Covariance Matrix\n",
    "#\n",
    "# load module with utility functions, including optimization \n",
    "import risk_opt_2Student as riskopt \n",
    "def tracking_error(wts_active,cov):\n",
    "    TE = np.sqrt(np.transpose(wts_active)@cov@wts_active)\n",
    "    return TE\n",
    "lamda = 0.94\n",
    "\n",
    "# Train the model (Training Set: 2000-12-31, 2008-12-31)\n",
    "ret_AllStock = ret_AllStock.iloc[0:2010,:]\n",
    "ret_Idx = ret_Idx.iloc[0:2010,:]\n",
    "\n",
    "#ret_AllStock = ret_AllStock.iloc[0:1935,:]\n",
    "#ret_Idx = ret_Idx.iloc[0:1935,:]\n",
    "\n",
    "num_periods, num_stock = ret_AllStock.shape\n",
    "# vol of the assets \n",
    "vols = ret_AllStock.std()\n",
    "rets_mean = ret_AllStock.mean()\n",
    "# demean the returns\n",
    "ret_AllStock = ret_AllStock - rets_mean\n",
    "\n",
    "# var_ewma calculation of the covraiance using the function from module risk_opt.py\n",
    "var_ewma = riskopt.ewma_cov(ret_AllStock, lamda)\n",
    "var_ewma_annual = var_ewma*252 #Annualize\n",
    "# take only the covariance matrix for the last date, which is the forecast for next time period\n",
    "cov_end = var_ewma[-1,:]\n",
    "#\n",
    "cov_end_annual = cov_end*252 #Annualize\n",
    "std_end_annual = np.sqrt(np.diag(cov_end))*np.sqrt(252)\n",
    "# calculate the correlation matrix\n",
    "corr = ret_AllStock.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this part shows the optimized weights and the minimized tracking error of the traing data.\n",
    "# We use the top 10 to 20 weighted stock to get the results\n",
    "# tracking error optimization\n",
    "#\n",
    "wts_active = np.zeros([num_stock,1])\n",
    "wts_active[0] = 0.05\n",
    "wts_active[-1] = -0.05\n",
    "#np.transpose(wts_active)@cov_end@wts_active\n",
    "TE1 = tracking_error(wts_active,cov_end)\n",
    "# The code above is only an example of calculating TE\n",
    "#\n",
    "# Test case - minize TE to zero should produce a fund with wts like those of the index\n",
    "\n",
    "num_topwtstock_2include = 10 #bad with 13, 16, 17, 18, 19, 20, 21,\n",
    "# only the top weight stocks + no shorting \n",
    "b1a_ = [(0.0,1.0) for i in range(num_topwtstock_2include)] \n",
    "# exclude bottom weighted stocks\n",
    "b1b_ = [(0.0,0.0) for i in range(num_topwtstock_2include,num_stock)] \n",
    "b1_ = b1a_ + b1b_ # combining the constraints\n",
    "# b1_[num_topwtstock_2include:-1] = (0.0,0.0)\n",
    "c1_ = ({'type':'eq', 'fun': lambda W: sum(W)-1. })  # Sum of active weights = 100%\n",
    "# Calling the optimizer\n",
    "wts_min_trackingerror1 = riskopt.opt_min_te(wts_Index, cov_end_annual, b1_, c1_)\n",
    "# calc TE achieved\n",
    "wts_active1 = wts_min_trackingerror1 - wts_Index\n",
    "TE_optimized1 = tracking_error(wts_active1,cov_end)\n",
    "print('{0} top weighted stock replication TE = {1:5.2f} bps'.format(num_topwtstock_2include, TE_optimized1*10000))\n",
    "\n",
    "# looping through number of stocks and save the history of TEs\n",
    "num_stock_b = 10\n",
    "num_stock_e = 21\n",
    "numstock_2use = range(num_stock_b,num_stock_e)\n",
    "wts_active_hist = np.zeros([len(numstock_2use), num_stock])\n",
    "TE_hist = np.zeros([len(numstock_2use), 1])\n",
    "count = 0\n",
    "# TE_hist is the minimized tracking error choosing different number of stocks\n",
    "\n",
    "for i in numstock_2use:\n",
    "    # only the top weight stocks + no shorting \n",
    "    b1_c_a_ = [(0.0,1.0) for j in range(i)] \n",
    "    # exclude bottom weighted stocks\n",
    "    b1_c_b_ = [(0.0,0.0) for j in range(i,num_stock)] \n",
    "    b1_curr_ = b1_c_a_ + b1_c_b_\n",
    "    wts_min_curr = riskopt.opt_min_te(wts_Index, cov_end_annual, b1_curr_, c1_)\n",
    "    wts_active_hist[count,:] = wts_min_curr.transpose()\n",
    "    TE_optimized_c = tracking_error(wts_min_curr-wts_Index,cov_end)\n",
    "    TE_hist[count,:] = TE_optimized_c*10000# in bps\n",
    "    count = count+1\n",
    "    \n",
    "    del b1_curr_, b1_c_a_, b1_c_b_,TE_optimized_c,wts_min_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here comes to the interesting part of the project.\n",
    "# We do not think it is reasonable to choose the top weighted stock ETF to track the equally-weighted index.\n",
    "# We guess that it might be much more efficient to randomly choose the stock but with fewer number of stocks\n",
    "# So we use the itertools.combinations to construct randomly chosen portfolio. # For example, if we randomly choose 2 stocks from 30 using the training data, there will be 435 scenario of combinations. \n",
    "# We calculate the optimized weight for each scenario and find the optimized weight matrix of the scenario which has smallest tracking error. \n",
    "# The optimized weight matrix we find above will be used directly to calculate the testing data tracking error.\n",
    "# The code in the following cell illustrate an example of 5 randomly chosen stock from which we get the optimized weight matrix and the tracking error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not using the TOP stocks\n",
    "#Try picking the stocks randomly\n",
    "    \n",
    "# which stocks should use?\n",
    "Flag_downloadData2 = False\n",
    "if Flag_downloadData2:\n",
    "    #TE_hist_own = np.zeros([435, 1])\n",
    "    #wts_active_hist_own = np.zeros([435, 30])\n",
    "    TE_hist_own = np.zeros([142506, 1])\n",
    "    wts_active_hist_own = np.zeros([142506, 30])\n",
    "    count = 0\n",
    "    \n",
    "    # Iterate each combination\n",
    "    for i in itertools.combinations(tickers, 5):\n",
    "    \n",
    "        # generate the constraints\n",
    "        b1_own = [(0.0,0.0) for n in range(30)]\n",
    "        for j in i:\n",
    "            colIndex = ret_AllStock.columns.get_loc(j)\n",
    "            b1_own[colIndex] = (0.0,1.0)\n",
    "        \n",
    "        wts_min_curr = riskopt.opt_min_te(wts_Index, cov_end_annual, b1_own, c1_)\n",
    "        wts_active_hist_own[count,:] = wts_min_curr.transpose()\n",
    "        TE_optimized_c = tracking_error(wts_min_curr-wts_Index,cov_end)\n",
    "        TE_hist_own[count,:] = TE_optimized_c*10000# in bps\n",
    "        count = count+1\n",
    "        \n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter('5Stocks.xlsx', engine='xlsxwriter')\n",
    "    pd.DataFrame(wts_active_hist_own).to_excel(writer, sheet_name='wts',startrow=0, startcol=0, header=True, index=True)\n",
    "    pd.DataFrame(TE_hist_own).to_excel(writer, sheet_name='TE',startrow=0, startcol=0, header=True, index=True)\n",
    "\n",
    "else:\n",
    "    wts_active_hist_own = pd.read_excel('5Stocks.xlsx', sheet_name='wts',\n",
    "                    header=0, index_col = 0)\n",
    "    TE_hist_own = pd.read_excel('5Stocks.xlsx', sheet_name='TE',\n",
    "                    header=0, index_col = 0)\n",
    "\n",
    "min_TE = TE_hist_own.min()\n",
    "min_Loc = np.where(TE_hist_own == min_TE)[0]\n",
    "optimized_comb = np.array(wts_active_hist_own)[min_Loc]\n",
    "print(min_TE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We use the training dataset to get our own ETF fund of 5 randomly chosen stock and compare the minimized TE to that of top weighted stocks. \n",
    "# We find the minimized TE of the randomly chosen ETF is still smaller than the top 14 weighted ETF\n",
    "# The result interprets the investment efficiency improvement by only holding a ETF of 5 stocks which has a better TE than the ETF of 14 stocks.\n",
    "# However, the time efficiency of our algorithms is quite low. To illustrate, if we want to randomly choose 10 stocks to reach a much smaller TE, we will spend more than a week to get the result from our algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the following parts, we start to calculate the TE for the testing data of the top weighted stocks and randomly chosen stocks respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the top weighted ETF model using test set  (Test Set: 2008-12-31, 2017-12-31)\n",
    "# Firstly is to calculate the covariance matrix for the test dataset\n",
    "# generate the return for test dataset\n",
    "ret_AllStock = daily_close_px.pct_change().dropna()\n",
    "ret_Idx = index_close_px.pct_change().dropna()\n",
    "ret_Idx.columns = ['Return']\n",
    "num_periods, num_stock = ret_AllStock.shape\n",
    "test_ret_AllStock = ret_AllStock.iloc[2010:,:]\n",
    "test_ret_Idx = ret_Idx.iloc[2010:,:]\n",
    "num_periods, num_stock = test_ret_AllStock.shape\n",
    "# calculate the vol and mean \n",
    "vols = test_ret_AllStock.std()\n",
    "rets_mean = test_ret_AllStock.mean()\n",
    "# demean the returns\n",
    "test_ret_AllStock = test_ret_AllStock - rets_mean\n",
    "# var_ewma calculation of the covraiance using the function from module risk_opt.py\n",
    "var_ewma = riskopt.ewma_cov(test_ret_AllStock, lamda)\n",
    "var_ewma_annual = var_ewma*252 #Annualize\n",
    "# take only the covariance matrix for the last date, which is the forecast for next time period\n",
    "test_cov_end = var_ewma[-1,:]\n",
    "test_cov_end_annual = test_cov_end*252 #Annualize\n",
    "test_std_end_annual = np.sqrt(np.diag(test_cov_end))*np.sqrt(252)\n",
    "# calculate the correlation matrix\n",
    "test_corr = test_ret_AllStock.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TE for test set (Top 10 stocks - Top 20 stocks)\n",
    "# use the training weight to calculate the new TE\n",
    "test_TE_hist = np.zeros([len(numstock_2use), 1])\n",
    "count = 0\n",
    "for i in numstock_2use:\n",
    "    # only the top weight stocks + no shorting \n",
    "    b1_c_a_ = [(0.0,1.0) for j in range(i)] \n",
    "    # exclude bottom weighted stocks\n",
    "    b1_c_b_ = [(0.0,0.0) for j in range(i,num_stock)] \n",
    "    b1_curr_ = b1_c_a_ + b1_c_b_\n",
    "    # using the weights from training covariance matrix\n",
    "    wts_min_curr = riskopt.opt_min_te(wts_Index, cov_end_annual, b1_curr_, c1_)\n",
    "    test_TE_optimized_c = tracking_error(wts_min_curr-wts_Index,test_cov_end)\n",
    "    test_TE_hist[count,:] = test_TE_optimized_c*10000# in bps\n",
    "    count = count+1\n",
    "\n",
    "    del b1_curr_, b1_c_a_, b1_c_b_,test_TE_optimized_c,wts_min_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TE for random five model\n",
    "# testing our own model using the latter part of our dataset\n",
    "own_test_TE = tracking_error(pd.Series(optimized_comb.transpose()[:,0])-wts_Index,test_cov_end)*10000\n",
    "print(own_test_TE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the following part, we will make some plots to better illustrate our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot bars of weights\n",
    "#\n",
    "figure_count = 1\n",
    "# ---  create plot of weights fund vs benchmark(top weighted model)---\n",
    "plt.figure(figure_count)\n",
    "figure_count = figure_count+1\n",
    "fig, ax = plt.subplots(figsize=(18,10))\n",
    "index = np.arange(len(wts_Index))\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, wts_Index, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Index Weight')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, wts_min_trackingerror1, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='ETF fund Weight')\n",
    " \n",
    "plt.xlabel('Ticker', fontsize=18)\n",
    "plt.ylabel('Weights', fontsize=18)\n",
    "plt.xticks(index + bar_width, (tickers), fontsize=12)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=18)\n",
    "plt.legend(fontsize=20)\n",
    "plt.title('Steve Tech ETF 10 vs.Benchmark',fontsize=18) \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('Steve Tech ETF 10 vs Benchmark.jpeg')\n",
    "#this bar chart only show the optimized wieght of ETF of 10 stock compared to the index\n",
    "\n",
    "#------plot TE as a function of number of stocks(top weighted model) -------------\n",
    "plt.figure(figure_count)\n",
    "figure_count = figure_count+1\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(range(num_stock_b,num_stock_e), TE_hist, 'b')\n",
    "plt.xlabel('Number of stocks in ETF', fontsize=18)\n",
    "plt.ylabel('Optimized Tracking Error (bps)', fontsize=18)\n",
    "plt.title('Steve Tech 30 ETF', fontsize=18)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=14)\n",
    "plt.title(\"Training Data TE\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the TE plot of traing dataset with the training data set(top-weighted model)\n",
    "plt.figure(figure_count)\n",
    "figure_count = figure_count+1\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(range(num_stock_b,num_stock_e), TE_hist, color='black',label=\"Training Data\")\n",
    "plt.plot(range(num_stock_b,num_stock_e),test_TE_hist, color='red',label=\"Testing Data\")\n",
    "plt.xlabel('Number of stocks in ETF', fontsize=18)\n",
    "plt.ylabel('Optimized Tracking Error (bps)', fontsize=18)\n",
    "plt.title('Steve Tech 30 ETF', fontsize=18)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=14)\n",
    "plt.title(\"Training Data TE vs Testing Data TE\", fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig(\"Training Data TE vs Testing Data TE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the bar chart weight using our own random chosen 5 stock\n",
    "plt.figure(figure_count)\n",
    "figure_count = figure_count+1\n",
    "fig, ax = plt.subplots(figsize=(18,10))\n",
    "index = np.arange(len(wts_Index))\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, wts_Index, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Index Weight')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, pd.Series(optimized_comb.transpose()[:,0]), bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='Steve Tech 5 ETF Weight')\n",
    " \n",
    "plt.xlabel('Ticker', fontsize=18)\n",
    "plt.ylabel('Weights', fontsize=18)\n",
    "plt.xticks(index + bar_width, (tickers), fontsize=12)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=18)\n",
    "plt.legend(fontsize=20)\n",
    "plt.title('Steve Tech ETF 5 vs Benchmark jpeg',fontsize=18) \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('Steve Tech ETF 5 vs Benchmark.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the TE traing data of top weighted vs randomly chosen\n",
    "min_TE_list=[52.252179]*11\n",
    "plt.figure(figure_count)\n",
    "figure_count = figure_count+1\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(range(num_stock_b,num_stock_e), TE_hist, color='black',label=\"Top Weighted Stock\")\n",
    "plt.plot(range(num_stock_b,num_stock_e),min_TE_list, color='red',label=\"Steve Tech 5\")\n",
    "plt.xlabel('Number of stocks in ETF', fontsize=18)\n",
    "plt.ylabel('Optimized Tracking Error (bps)', fontsize=18)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=14)\n",
    "plt.title(\"Training Data\", fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig(\"Training Data_Steve Tech 5 vs Top weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the TE testing data of top weighted vs randomly chosen\n",
    "own_test_TE_list=[35.45713253022448]*11\n",
    "plt.figure(figure_count)\n",
    "figure_count = figure_count+1\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(range(num_stock_b,num_stock_e), test_TE_hist, color='black',label=\"Top Weighted Stock\")\n",
    "plt.plot(range(num_stock_b,num_stock_e),own_test_TE_list, color='red',label=\"Steve Tech 5\")\n",
    "plt.xlabel('Number of stocks in ETF', fontsize=18)\n",
    "plt.ylabel('Optimized Tracking Error (bps)', fontsize=18)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=14)\n",
    "plt.title(\"Testing Data\", fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig(\"Testing Data_Steve Tech 5 vs Top weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More to think about:\n",
    "# Is it a more efficient algorithsm to randomly construct the ETF?\n",
    "# What is the reason for a better result from testing data?\n",
    "# Is it more optimal to do the dynamic tracking error?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
